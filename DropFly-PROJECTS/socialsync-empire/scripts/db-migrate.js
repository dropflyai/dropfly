#!/usr/bin/env node

/**
 * Simple Database Migration Runner
 * Uses fetch to POST SQL directly to Supabase
 */

const fs = require('fs');
const path = require('path');
require('dotenv').config({ path: '.env.local' });

const SUPABASE_URL = process.env.NEXT_PUBLIC_SUPABASE_URL;
const SERVICE_KEY = process.env.SUPABASE_SERVICE_ROLE_KEY;
const PROJECT_REF = SUPABASE_URL?.split('//')[1]?.split('.')[0];

if (!SUPABASE_URL || !SERVICE_KEY) {
  console.error('âŒ Missing Supabase credentials in .env.local');
  process.exit(1);
}

// Execute SQL using Supabase database API
async function executeSQL(sql, description) {
  console.log(`\nðŸ”„ ${description}...`);

  // Use Supabase's database API endpoint
  const endpoint = `https://${PROJECT_REF}.supabase.co/rest/v1/rpc`;

  try {
    // First, we need to create an exec function if it doesn't exist
    // This is a one-time setup
    const createExecFunction = `
      CREATE OR REPLACE FUNCTION exec(sql text)
      RETURNS json
      LANGUAGE plpgsql
      SECURITY DEFINER
      AS $$
      DECLARE
        result json;
      BEGIN
        EXECUTE sql;
        RETURN json_build_object('success', true);
      END;
      $$;
    `;

    // Try to create the function first (will fail silently if exists)
    try {
      const setupResponse = await fetch(endpoint, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'apikey': SERVICE_KEY,
          'Authorization': `Bearer ${SERVICE_KEY}`,
          'Prefer': 'return=representation'
        },
        body: JSON.stringify({
          name: 'exec',
          params: { sql: createExecFunction }
        })
      });
    } catch (e) {
      // Ignore - function might already exist
    }

    // Now execute the actual SQL
    const response = await fetch(endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'apikey': SERVICE_KEY,
        'Authorization': `Bearer ${SERVICE_KEY}`,
        'Prefer': 'return=representation'
      },
      body: JSON.stringify({
        name: 'exec',
        params: { sql }
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`HTTP ${response.status}: ${errorText}`);
    }

    const result = await response.json();
    console.log(`âœ… ${description} - SUCCESS`);
    return true;

  } catch (error) {
    console.error(`âŒ ${description} - FAILED:`);
    console.error('  ', error.message);
    return false;
  }
}

// Get migration files
function getMigrationFiles() {
  const migrationsDir = path.join(__dirname, '..', 'supabase', 'migrations');

  if (!fs.existsSync(migrationsDir)) {
    console.error(`âŒ Migrations directory not found: ${migrationsDir}`);
    process.exit(1);
  }

  const files = fs.readdirSync(migrationsDir)
    .filter(file => file.endsWith('.sql'))
    .sort();

  return files.map(file => ({
    name: file,
    sql: fs.readFileSync(path.join(migrationsDir, file), 'utf8')
  }));
}

// Main function
async function main() {
  console.log('ðŸš€ Database Migration Runner');
  console.log('ðŸ“ Project:', PROJECT_REF);
  console.log('');

  const migrations = getMigrationFiles();
  console.log(`ðŸ“¦ Found ${migrations.length} migration file(s)\n`);

  let successCount = 0;
  let failCount = 0;

  for (const migration of migrations) {
    const success = await executeSQL(migration.sql, `Applying ${migration.name}`);
    if (success) {
      successCount++;
    } else {
      failCount++;
    }
  }

  console.log('\n' + '='.repeat(60));
  console.log(`âœ… Successful: ${successCount}`);
  console.log(`âŒ Failed: ${failCount}`);
  console.log('='.repeat(60));

  if (failCount === 0) {
    console.log('\nâœ… All migrations completed successfully!');
    console.log('ðŸ‘‰ Restart your dev server to apply changes\n');
  } else {
    console.log('\nâš ï¸  Some migrations failed. See errors above.\n');
    process.exit(1);
  }
}

main().catch(error => {
  console.error('\nðŸ’¥ Migration runner error:', error.message);
  process.exit(1);
});
